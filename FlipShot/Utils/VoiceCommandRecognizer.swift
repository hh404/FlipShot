import AVFoundation
import Foundation
import Speech

final class VoiceCommandRecognizer: NSObject {

    // MARK: - Types

    enum Command: String {
        case up, down, left, right
        case `continue`, next

        var display: String {
            switch self {
            case .up: return "ä¸Š"
            case .down: return "ä¸‹"
            case .left: return "å·¦"
            case .right: return "å³"
            case .continue: return "ç»§ç»­"
            case .next: return "ä¸‹ä¸€ä¸ª"
            }
        }

        var isDirection: Bool {
            switch self {
            case .up, .down, .left, .right: return true
            case .continue, .next: return false
            }
        }

        var isSeparator: Bool {
            switch self {
            case .continue, .next: return true
            case .up, .down, .left, .right: return false
            }
        }
    }

    enum Phase {
        case direction
        case separator
    }

    enum CueState {
        case idle
        case cooldown(remaining: TimeInterval)
        case awaitingDirection
        case awaitingSeparator
    }

    struct Config {
        var locale = Locale(identifier: "zh-CN")

        /// æ–¹å‘è¯è§¦å‘åï¼Œå¤šä¹…æ‰å…è®¸ä¸‹ä¸€æ¬¡æ–¹å‘è¯ï¼ˆåœ¨ separator è§£é”åç”Ÿæ•ˆï¼‰
        var cooldownSeconds: TimeInterval = 0.8

        /// é™é»˜è¿™ä¹ˆä¹…ï¼ˆæ— æ–° partial æ›´æ–°ï¼‰å°±æŠŠæœ€åä¸€æ¬¡ partial å½“ final åŒ¹é…ï¼›åŒ€é€Ÿè¯´è¯æ—¶è‹¥è¯†åˆ«å™¨æ›´æ–°æœ‰é—´éš”ï¼Œå»ºè®® â‰¥2s å‡å°‘è¯¯è§¦å‘
        var silenceAutoFinalSeconds: TimeInterval = 1.2

        /// æ—¥å¿—å»é‡ï¼ˆåŒä¸€æ–‡æœ¬çŸ­æ—¶é—´é‡å¤ä¸åˆ·å±ï¼‰
        var logDedupSeconds: TimeInterval = 0.8

        /// åªåœ¨æ–‡æœ¬å¾ˆçŸ­æ—¶æ‰åšæ–¹å‘è¯å³æ—¶åŒ¹é…ï¼Œé¿å…â€œä¸Šä¸€ä¸ª/å·¦è¾¹â€é‚£ç§é•¿å¥ä¹±è§¦å‘
        /// ä½†ä½ åˆéœ€è¦æ”¯æŒâ€œå·¦è¾¹â€ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨æ‹¼éŸ³å‰ç¼€åŒ¹é…ï¼Œå¹¶å…è®¸çŸ­è¯­
        var maxImmediateCharsForDirection: Int = 6
    }

    // MARK: - Callbacks

    var onLog: ((String) -> Void)?
    var onTranscript: ((String, Bool) -> Void)?
    var onCueStateChanged: ((CueState) -> Void)?
    var onCommand: ((Command) -> Void)?              // æ–¹å‘è¯ & åˆ†éš”è¯éƒ½ä¼šå›è°ƒ
    var onDirectionCommand: ((Command) -> Void)?     // ä»…æ–¹å‘è¯
    /// true = è¯†åˆ«åŸæ–‡å·²æœ‰ã€æ­£åœ¨ç®—æœ¬å¥ç­”æ¡ˆï¼›false = å¤„ç†å®Œã€‚ç”¨äº UI æ˜¾ç¤ºã€Œæ­£åœ¨å¤„ç†ä¸­ã€é¿å…ç”¨æˆ·ä»¥ä¸ºæ²¡å¬è§
    var onProcessing: ((Bool) -> Void)?
    var onErrorText: ((String) -> Void)?
    var onPermissionChanged: ((Bool, Bool) -> Void)?

    // MARK: - State

    private let config: Config
    private let speechRecognizer: SFSpeechRecognizer?

    private let audioEngine = AVAudioEngine()
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?

    private var phase: Phase = .direction
    private(set) var isRecognizing = false

    private var hasMicAuth = false
    private var hasSpeechAuth = false
    private var hasMicResultReceived = false
    private var hasSpeechResultReceived = false

    private var cueTimer: Timer?
    private var silenceTimer: Timer?
    private var lastPartialTextForTimeout: String?
    /// ä¸Šæ¬¡å·²æäº¤çš„è¯†åˆ«åŸæ–‡ï¼ˆtryMatch ç”¨è¿‡çš„ï¼‰ï¼Œç”¨äºä¸å½“å‰åŸæ–‡ diffï¼ŒåŠæ—¶æ›´æ–°ã€Œæ­£åœ¨å¤„ç†ä¸­ã€
    private var lastCommittedTranscript = ""

    private var directionCooldownUntil = Date.distantPast

    private var lastLoggedText = ""
    private var lastLoggedAt = Date.distantPast

    private lazy var logFormatter: DateFormatter = {
        let f = DateFormatter()
        f.dateFormat = "HH:mm:ss"
        return f
    }()

    static let shared = VoiceCommandRecognizer()

    init(config: Config = .init()) {
        self.config = config
        self.speechRecognizer = SFSpeechRecognizer(locale: config.locale)
        super.init()
    }

    deinit {
        stop()
    }

    // MARK: - Permissions

    func requestPermissions() {
        hasMicResultReceived = false
        hasSpeechResultReceived = false

        AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in
            DispatchQueue.main.async {
                guard let self else { return }
                self.hasMicAuth = granted
                self.hasMicResultReceived = true
                self.firePermissionChangedIfReady()
            }
        }

        SFSpeechRecognizer.requestAuthorization { [weak self] status in
            DispatchQueue.main.async {
                guard let self else { return }
                self.hasSpeechAuth = (status == .authorized)
                self.hasSpeechResultReceived = true
                self.firePermissionChangedIfReady()
            }
        }
    }

    private func firePermissionChangedIfReady() {
        guard hasMicResultReceived && hasSpeechResultReceived else { return }
        onPermissionChanged?(hasMicAuth, hasSpeechAuth)
    }

    // MARK: - Public Controls

    func start() {
        guard hasMicAuth && hasSpeechAuth else {
            onErrorText?("ç¼ºå°‘æƒé™(éº¦å…‹é£æˆ–è¯­éŸ³è¯†åˆ«)")
            return
        }
        guard let speechRecognizer, speechRecognizer.isAvailable else {
            onErrorText?("è¯­éŸ³è¯†åˆ«å½“å‰ä¸å¯ç”¨")
            return
        }

        // ç»Ÿä¸€éŸ³é¢‘ä¼šè¯ï¼ˆå»ºè®® measurementï¼Œå°½é‡å‡å°‘ç³»ç»Ÿå¤„ç†å¸¦æ¥çš„ä¸ç¡®å®šæ€§ï¼‰
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.record, mode: .measurement, options: [.duckOthers])
            try session.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            onErrorText?("éŸ³é¢‘ä¼šè¯å¤±è´¥: \(error.localizedDescription)")
            return
        }

        isRecognizing = true
        phase = .direction
        directionCooldownUntil = Date() // å…è®¸ç«‹å³è¯´æ–¹å‘
        emitLog("å¼€å§‹è¯†åˆ«ï¼ˆä¸¤é˜¶æ®µï¼šDirection â†’ Separatorï¼‰")

        startCueTimer()
        startRecognitionPipeline(for: .direction)
        emitCue()
    }

    func stop() {
        stopRecognitionPipeline()
        isRecognizing = false
        stopCueTimer()
        cancelSilenceTimer()
        lastPartialTextForTimeout = nil
        phase = .direction
        directionCooldownUntil = .distantPast
        emitCue()
        emitLog("åœæ­¢è¯†åˆ«")
    }

    /// ä¸‹ä¸€é¢˜ï¼šæ¸…ç©ºçŠ¶æ€ï¼Œå…è®¸ç«‹å³æ–¹å‘è¯
    func clearForNextInput() {
        phase = .direction
        directionCooldownUntil = Date()
        cancelSilenceTimer()
        lastPartialTextForTimeout = nil
        emitCue()
    }

    /// ç­”é”™åï¼šå…è®¸ç«‹å³å†è¯´æ–¹å‘è¯
    func allowDirectionAgain() {
        phase = .direction
        directionCooldownUntil = Date()
        cancelSilenceTimer()
        lastPartialTextForTimeout = nil
        // é‡å¯æ–¹å‘é˜¶æ®µï¼Œå½»åº•æ¸…ç©ºæ—§è½¬å†™ï¼ˆé¿å…â€œè¯†åˆ«è¿‡çš„â€æ®‹ç•™ï¼‰
        if isRecognizing {
            startRecognitionPipeline(for: .direction)
        }
        emitCue()
    }

    // MARK: - Pipeline

    private func startRecognitionPipeline(for newPhase: Phase) {
        phase = newPhase
        cancelSilenceTimer()
        lastPartialTextForTimeout = nil

        // ä»…é‡å¯æ—¶æ¸…ç†ä¸Šä¸€è½® request/task/tapï¼Œé¦–æ¬¡å¯åŠ¨ä¸ç¢°
        if recognitionRequest != nil || recognitionTask != nil {
            recognitionRequest?.endAudio()
            recognitionRequest = nil
            recognitionTask?.cancel()
            recognitionTask = nil
            audioEngine.inputNode.removeTap(onBus: 0)
        }

        let request = SFSpeechAudioBufferRecognitionRequest()
        request.shouldReportPartialResults = true   // è¦ partialï¼Œé™é»˜è¶…æ—¶æ‰èƒ½å½“ final
        request.requiresOnDeviceRecognition = true  // æœ¬æœºè¯†åˆ«ï¼Œéšç§ä¸”å¯ç¦»çº¿

        recognitionRequest = request

        let inputNode = audioEngine.inputNode
        inputNode.installTap(onBus: 0,
                             bufferSize: 1024,
                             format: inputNode.outputFormat(forBus: 0)) { [weak self] buffer, _ in
            self?.recognitionRequest?.append(buffer)
        }

        if !audioEngine.isRunning {
            audioEngine.prepare()
            do {
                try audioEngine.start()
            } catch {
                onErrorText?("å¯åŠ¨å½•éŸ³å¤±è´¥: \(error.localizedDescription)")
                return
            }
        }

        emitLog("è¿›å…¥é˜¶æ®µï¼š\(newPhase == .direction ? "ç­‰å¾…æ–¹å‘è¯" : "ç­‰å¾…åˆ†éš”è¯")")

        recognitionTask = speechRecognizer?.recognitionTask(with: request) { [weak self] result, error in
            guard let self else { return }
            DispatchQueue.main.async {
                if let result {
                    let text = result.bestTranscription.formattedString
                    let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
                    let isDuplicate = !trimmed.isEmpty && trimmed == self.lastCommittedTranscript

                    if !trimmed.isEmpty && !isDuplicate {
                        self.onProcessing?(true)
                    }
                    if isDuplicate {
                        self.onTranscript?("", false)
                    } else {
                        self.onTranscript?(text, result.isFinal)
                    }

                    if result.isFinal {
                        self.emitLog("è¯†åˆ«(final): \(text)")
                        if !isDuplicate {
                            self.tryMatch(text: text, isFinal: true)
                        } else {
                            self.emitLog("è·³è¿‡é‡å¤ finalï¼Œå·²æäº¤è¿‡: \(text)")
                        }
                    } else {
                        self.emitLog("è¯†åˆ«(partial): \(text) â†’ è‹¥ \(self.config.silenceAutoFinalSeconds)s å†…æ— æ–°ç»“æœå°†å½“ final")
                    }

                    self.lastPartialTextForTimeout = text
                    if !isDuplicate {
                        self.scheduleSilenceTimer()
                    }
                }

                if let error {
                    self.emitLog("è¯†åˆ«æŠ¥é”™: \(error.localizedDescription)")
                    guard self.isRecognizing else {
                        self.stop()
                        return
                    }
                    // No speech detected æ—¶ç«‹å³é‡å¯ä¼šæ­»å¾ªç¯ï¼Œå»¶è¿Ÿ 1 ç§’å†é‡å¯ï¼Œæ–¹ä¾¿ç”¨æˆ·è¯´ã€Œç»§ç»­ã€
                    let isNoSpeech = error.localizedDescription.contains("No speech detected") || error.localizedDescription.contains("no speech")
                    if isNoSpeech {
                        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
                            guard let self, self.isRecognizing else { return }
                            self.emitLog("No speech åå»¶è¿Ÿé‡å¯")
                            self.startRecognitionPipeline(for: self.phase)
                            self.emitCue()
                        }
                    } else {
                        self.startRecognitionPipeline(for: self.phase)
                        self.emitCue()
                    }
                }
            }
        }
    }

    private func stopRecognitionPipeline() {
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        recognitionRequest?.endAudio()
        recognitionRequest = nil
        recognitionTask?.cancel()
        recognitionTask = nil
    }

    // MARK: - Matching

    /// ä»…ç”¨äºå•å…ƒæµ‹è¯•ï¼šå°†é˜¶æ®µé‡ç½®ä¸ºâ€œç­‰å¾…æ–¹å‘è¯â€å¹¶å¯¹æ–‡æœ¬æ‰§è¡Œä¸€æ¬¡ final åŒ¹é…ï¼ˆä¸ç»è¿‡è¯­éŸ³å¼•æ“ï¼‰
    func processTextForTest(_ text: String) {
        phase = .direction
        directionCooldownUntil = Date.distantPast
        tryMatch(text: text, isFinal: true)
    }

    private func tryMatch(text: String, isFinal: Bool) {
        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmed.isEmpty else { return }

        if isFinal {
            onProcessing?(true)
            defer { onProcessing?(false) }
        }
        emitLogDedup("è¯†åˆ«(\(isFinal ? "final" : "partial")): \(trimmed)")

        let pinyin = toPinyin(trimmed)
        var remaining = pinyin
        let maxRounds = 30
        var rounds = 0
        var lastMatchedCommand: Command?
        var lastDirectionInSentence: Command?  // æœ¬å¥æœ€åä¸€ä¸ªæ–¹å‘ = ç­”æ¡ˆï¼Œåªå›è°ƒä¸€æ¬¡

        while rounds < maxRounds {
            rounds += 1
            let s = normalize(remaining)

            let dirMatch = matchDirection(normalized: s)
            let sepMatch = matchSeparatorWithRange(normalized: s)

            let chosen: (Command, Range<String.Index>)?
            switch (dirMatch, sepMatch) {
            case let (d?, s?):
                chosen = d.2.lowerBound <= s.2.lowerBound ? (d.0, d.2) : (s.0, s.2)
            case let (d?, _):
                chosen = (d.0, d.2)
            case let (_, s?):
                chosen = (s.0, s.2)
            case (nil, nil):
                chosen = nil
            }

            guard let (c, r) = chosen else { break }
            if c.isDirection, isRecognizing, Date() < directionCooldownUntil { break }

            emitCommand(c)
            lastMatchedCommand = c
            if c.isDirection { lastDirectionInSentence = c }
            remaining = String(s[..<r.lowerBound]) + String(s[r.upperBound...])
            if remaining.isEmpty { break }
        }
        if let lastDir = lastDirectionInSentence {
            onDirectionCommand?(lastDir)
            emitLog("æœ¬å¥ç­”æ¡ˆ(æœ€åæ–¹å‘): \(lastDir.display)")
        }
        if let last = lastMatchedCommand {
            emitLog("æœ¬å¥æœ€åå‘½ä¸­: \(last.display)ï¼Œä¸‹ä¸€é˜¶æ®µ: \(last.isDirection ? "ç­‰å¾…åˆ†éš”è¯" : "ç­‰å¾…æ–¹å‘è¯")")
            applyPhaseAfterMatch(last)
        }
        lastCommittedTranscript = trimmed
    }

    /// ä»æ‹¼éŸ³ä¸²ä¸­ç§»é™¤é¦–æ¬¡å‡ºç°çš„åŒ¹é…å­ä¸²ï¼ˆç”¨äºåˆ†éš”è¯æ¶ˆè€—ï¼‰
    private func consumeMatch(from pinyin: String, matched: String) -> String {
        let s = normalize(pinyin)
        guard let r = s.range(of: matched) else { return pinyin }
        return String(s[r.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
    }

    /// é™é»˜åˆ°ç‚¹ï¼ŒæŠŠæœ€åä¸€æ¬¡ partial å½“ final å†è§¦å‘ä¸€æ¬¡ï¼ˆé˜²æ­¢ç³»ç»Ÿè¿Ÿè¿Ÿä¸ç»™ finalï¼‰
    private func fireSilenceAutoFinal() {
        cancelSilenceTimer()
        guard isRecognizing else { return }
        guard let text = lastPartialTextForTimeout?.trimmingCharacters(in: .whitespacesAndNewlines),
              !text.isEmpty else { return }

        emitLog("é™é»˜ \(config.silenceAutoFinalSeconds)sï¼ŒæŒ‰ final å¤„ç†: \(text)")
        tryMatch(text: text, isFinal: true)
    }

    /// åªåš onCommand ä¸æ—¥å¿—ï¼›æ–¹å‘è¯ä¸åœ¨æ­¤å¤„å›è°ƒ onDirectionCommandï¼Œå¥æœ«ç»Ÿä¸€å›è°ƒæœ¬å¥æœ€åæ–¹å‘ä¸€æ¬¡
    private func emitCommand(_ command: Command) {
        if command.isDirection {
            emitLog("å‘½ä¸­æ–¹å‘è¯: \(command.display)")
            onCommand?(command)
        } else {
            emitLog("å‘½ä¸­åˆ†éš”è¯: \(command.display)ï¼ˆè§£é”ä¸‹ä¸€æ¬¡æ–¹å‘è¯ï¼‰")
            onCommand?(command)
        }
    }

    /// æ ¹æ®æœ¬å¥æœ€åå‘½ä¸­çš„ token æ›´æ–° phase ä¸å†·å´ï¼ˆä»…å¥æœ«æ‰§è¡Œä¸€æ¬¡ï¼‰
    private func applyPhaseAfterMatch(_ command: Command) {
        cancelSilenceTimer()
        lastPartialTextForTimeout = nil
        if command.isDirection {
            phase = .separator
            emitLog("è¿›å…¥é˜¶æ®µï¼šç­‰å¾…åˆ†éš”è¯ï¼ˆä¸‹ä¸€å¥éœ€è¯´ ç»§ç»­ï¼‰")
            emitCue()
        } else {
            if isRecognizing {
                directionCooldownUntil = Date().addingTimeInterval(config.cooldownSeconds)
            }
            phase = .direction
            emitLog("è¿›å…¥é˜¶æ®µï¼šç­‰å¾…æ–¹å‘è¯ï¼ˆä¸é‡å¯ç®¡é“ï¼‰")
            emitCue()
        }
    }

    private func handleCommand(_ command: Command) {
        emitCommand(command)
        applyPhaseAfterMatch(command)
    }

    // MARK: - Match Rules (Pinyin)

    /// æ–¹å‘ï¼šæŒ‰å‡ºç°é¡ºåºå–ç¬¬ä¸€ä¸ªæ–¹å‘è¯ï¼ˆè§„åˆ™è¡¨è¦æ±‚æ–¹å‘åºåˆ—ä¸ºé¡ºåºï¼‰ã€‚è¿”å› (å‘½ä»¤, åŒ¹é…å‰ç¼€, åœ¨å½’ä¸€åŒ–ä¸²ä¸­çš„èŒƒå›´)ã€‚
    private func matchDirection(normalized s: String) -> (Command, String, Range<String.Index>)? {
        guard !s.isEmpty else { return nil }

        let groups: [(Command, [String])] = [
            (.up, ["shang", "sha", "sang", "xiang"]),  // å‘ â†’ ä¸Š
            (.down, ["xia", "hia"]),  // ä¸ç”¨ "xi"ï¼Œé¿å…ã€Œå‘ã€xiang è¯¯å‘½ä¸­
            (.left, ["zuo", "zu", "zhuo"]),
            (.right, ["you", "yo", "iu"])
        ]
        var firstMatch: (range: Range<String.Index>, command: Command, prefix: String)?
        for (cmd, prefixes) in groups {
            for p in prefixes {
                let r: Range<String.Index>?
                if p == "xia" {
                    var start = s.startIndex
                    var found: Range<String.Index>?
                    while let rr = s.range(of: "xia", range: start..<s.endIndex) {
                        if !s[rr.lowerBound...].hasPrefix("xiang") {
                            found = rr
                            break
                        }
                        start = rr.upperBound
                    }
                    r = found
                } else {
                    r = s.range(of: p)
                }
                guard let r = r else { continue }
                if let e = firstMatch {
                    if r.lowerBound < e.range.lowerBound { firstMatch = (r, cmd, p) }
                } else {
                    firstMatch = (r, cmd, p)
                }
            }
        }
        guard let first = firstMatch else { return nil }
        return (first.command, first.prefix, first.range)
    }

    /// åˆ†éš”è¯ï¼šä»… ç»§ç»­ï¼ˆä¸åŒ¹é…ã€Œä¸‹ä¸€ä¸ªã€ï¼Œé¿å…ä¸ã€Œä¸‹ã€å†²çªï¼‰ã€‚è¿”å› (å‘½ä»¤, é¦–æ¬¡åŒ¹é…å­ä¸², èŒƒå›´) ä¾¿äºä¸æ–¹å‘æ¯”è°æ›´é å‰ã€‚
    private func matchSeparatorWithRange(normalized s: String) -> (Command, String, Range<String.Index>)? {
        guard !s.isEmpty else { return nil }

        let groups: [(Command, [String])] = [
            (.continue, ["jixu", "jixuyixia", "jixuba", "jixv", "jixÃ¼", "continue"])
        ]
        var earliest: (range: Range<String.Index>, command: Command, part: String)?
        for (cmd, parts) in groups {
            for p in parts {
                guard let r = s.range(of: p) else { continue }
                if let e = earliest {
                    if r.lowerBound < e.range.lowerBound { earliest = (r, cmd, p) }
                } else {
                    earliest = (r, cmd, p)
                }
            }
        }
        guard let e = earliest else { return nil }
        return (e.command, e.part, e.range)
    }

    private func firstPrefix(_ s: String, _ prefixes: [String]) -> String? {
        for p in prefixes where s.hasPrefix(p) { return p }
        return nil
    }

    private func firstContained(_ s: String, _ parts: [String]) -> String? {
        var earliest: (range: Range<String.Index>, part: String)?
        for p in parts {
            guard let r = s.range(of: p) else { continue }
            if let e = earliest {
                if r.lowerBound < e.range.lowerBound { earliest = (r, p) }
            } else {
                earliest = (r, p)
            }
        }
        return earliest?.part
    }

    private func normalize(_ s: String) -> String {
        s.lowercased().filter { !$0.isWhitespace && !$0.isPunctuation }
    }

    // MARK: - Pinyin

    /// å°†ä¸­æ–‡è½¬æ‹¼éŸ³ï¼›å¦‚æœåŸæœ¬å°±æ˜¯æ‹¼éŸ³/ASCIIï¼Œåˆ™ç›´æ¥å½’ä¸€åŒ–è¿”å›
    private func toPinyin(_ text: String) -> String {
        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmed.isEmpty else { return "" }

        // ä»…å½“æ•´å¥éƒ½æ˜¯ ASCIIï¼ˆå¦‚ next / zuoï¼‰æ—¶ç›´æ¥å½’ä¸€åŒ–ï¼Œå¦åˆ™è½¬æ‹¼éŸ³ï¼ˆå«ã€Œä¸Šxã€ã€Œxä¸Šã€ç­‰æ··æ’ï¼‰
        let asciiCount = trimmed.unicodeScalars.filter { $0.isASCII }.count
        if asciiCount == trimmed.unicodeScalars.count {
            return normalize(trimmed)
        }

        let lower = trimmed.lowercased()
        let filtered = lower.filter { !$0.isWhitespace && !$0.isPunctuation }
        let mutable = NSMutableString(string: filtered) as CFMutableString
        CFStringTransform(mutable, nil, kCFStringTransformToLatin, false)
        CFStringTransform(mutable, nil, kCFStringTransformStripCombiningMarks, false)
        return (mutable as String).replacingOccurrences(of: " ", with: "")
    }

    // MARK: - Cue / Timers

    private func emitCue() {
        guard isRecognizing else {
            onCueStateChanged?(.idle)
            return
        }

        if phase == .direction, Date() < directionCooldownUntil {
            onCueStateChanged?(.cooldown(remaining: max(directionCooldownUntil.timeIntervalSinceNow, 0)))
            return
        }

        switch phase {
        case .direction:
            onCueStateChanged?(.awaitingDirection)
        case .separator:
            onCueStateChanged?(.awaitingSeparator)
        }
    }

    private func startCueTimer() {
        stopCueTimer()
        cueTimer = Timer.scheduledTimer(withTimeInterval: 0.2, repeats: true) { [weak self] _ in
            self?.emitCue()
        }
        RunLoop.main.add(cueTimer!, forMode: .common)
    }

    private func stopCueTimer() {
        cueTimer?.invalidate()
        cueTimer = nil
    }

    private func scheduleSilenceTimer() {
        cancelSilenceTimer()
        silenceTimer = Timer.scheduledTimer(withTimeInterval: config.silenceAutoFinalSeconds, repeats: false) { [weak self] _ in
            self?.fireSilenceAutoFinal()
        }
        RunLoop.main.add(silenceTimer!, forMode: .common)
    }

    private func cancelSilenceTimer() {
        silenceTimer?.invalidate()
        silenceTimer = nil
    }

    // MARK: - Logging

    private func emitLog(_ message: String) {
        let line = "[\(logFormatter.string(from: Date()))] \(message)"
        print("ğŸ¤ \(line)")
        onLog?(line)
    }

    private func emitLogDedup(_ message: String) {
        let now = Date()
        if message == lastLoggedText, now.timeIntervalSince(lastLoggedAt) < config.logDedupSeconds {
            return
        }
        lastLoggedText = message
        lastLoggedAt = now
        emitLog(message)
    }
}
